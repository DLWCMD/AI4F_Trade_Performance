{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinRL_HP_Tuning_Trade Performance_with_Optuna .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwrAr8vEmP2M"
      },
      "source": [
        "# INTRODUCTION\n",
        "1. In this tutorial, we will be tuning hyperparameters for Stable baselines3 models using Optuna.\n",
        "2. The default model hyperparamters may not be adequate for your custom portfolio or custom state-space. Reinforcement learning algorithms are sensitive to hyperparamters, hence tuning is an important step.\n",
        "3. Hyperparamters are tuned based on an objective, which needs to be maximized or minimized. ***In this version, the ratio of average winning to losing trade value is used as the objective.***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "avdupku_JcK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRF-7Vp5NCjU"
      },
      "source": [
        "#Installing FinRL\n",
        "# Set colab status to trigger installs\n",
        "clb = True\n",
        "n_trials = 25\n",
        "dl_prices = False\n",
        "read_data = True\n",
        "tpm_hist = {}  # record tp metric values for trials\n",
        "print(f'Preparing for colab: {clb}')\n",
        "pkgs = ['FinRL', 'optuna', 'Ray/rllib','plotly','ipywidgets']\n",
        "total_timesteps = 25000\n",
        "lc_threshold=1e-5\n",
        "lc_patience=15\n",
        "lc_trial_number=5\n",
        "tp_metric = 'avgwl'  # average trade win $/loss $\n",
        "if clb:\n",
        "    print(f'Installing packages: {pkgs}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#!pip install unzip\n",
        "import shutil\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "def upload_prices():\n",
        "  uploaded = files.upload() \n",
        "\n",
        "download_data=True\n",
        "read_data=True\n",
        "\n",
        "# check if prices available\n",
        "if exists(\"/content/DOW_prices_20211229-20h35.csv\"):\n",
        "  print('prices already loaded')\n",
        "  download_data=False\n",
        "  read_data=True\n",
        "  try:\n",
        "    os.remove(\"/content/DOW_prices_20211229-20h35.csv.zip\")\n",
        "  except:\n",
        "    print('Not found')\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/__MACOSX\")\n",
        "  except:\n",
        "    print('Not found')\n",
        "\n",
        "elif exists(\"/content/DOW_prices_20211229-20h35.csv.zip\"):\n",
        "  print('Found zipped prices')\n",
        "  ! unzip -uq \"/content/DOW_prices_20211229-20h35.csv.zip\" -d \"/content\"\n",
        "  download_data = False\n",
        "  read_data=True\n",
        "  \n",
        "else:\n",
        "  download_data = False\n",
        "  uploaded = files.upload() \n",
        "! unzip -uq \"/content/DOW_prices_20211229-20h35.csv.zip\" -d \"/content\"\n",
        "  \n"
      ],
      "metadata": {
        "id": "K1IeHqgzb4ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "if not download_data and read_data:\n",
        "  df = pd.read_csv('/content/DOW_prices_20211229-20h35.csv',index_col=0)\n",
        "  print(df.shape)\n",
        "  \n",
        "elif download_data:\n",
        "  #Custom ticker list dataframe download\n",
        "  ticker_list = config.DOW_30_TICKER\n",
        "  df = YahooDownloader(start_date = '2009-01-01',\n",
        "                       end_date = '2021-10-01',\n",
        "                       ticker_list = ticker_list).fetch_data()\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "jgUTu_VJ15yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        " %%capture\n",
        "   \n",
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
        "!pip install optuna\n",
        "!pip install -U \"ray[rllib]\"\n",
        "!pip install plotly\n",
        "!pip install ipywidgets\n",
        "!pip install -U kaleido"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bSLdukRZmzHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "import optuna\n",
        "%matplotlib inline\n",
        "from finrl.apps import config\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading_np import StockTradingEnv as StockTradingEnv_numpy\n",
        "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.drl_agents.rllib.models import DRLAgent as DRLAgent_rllib\n",
        "from finrl.finrl_meta.data_processor import DataProcessor\n",
        "import joblib\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "import ray\n",
        "from pprint import pprint\n",
        "import kaleido\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(f'Torch device: {device}')\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ShYEIr-umzHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "v0sD-98_8PkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_fCHS6NMx9"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71P6jMlEpikl"
      },
      "source": [
        "## COLLECTING DATA AND PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mGr_mSz14Wwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if dl_prices:\n",
        "  now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "  df.to_csv(\"./\"+config.RESULTS_DIR+\"/DOW_prices_\" +now+ '.csv')"
      ],
      "metadata": {
        "id": "0z-C1Fcx4Ou1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cntKg5nWO5qn"
      },
      "source": [
        "#You can add technical indicators and turbulence factor to dataframe\n",
        "#Just set the use_technical_indicator=True, use_vix=True and use_turbulence=True\n",
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5diXih4zPE6m"
      },
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist()\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)\n",
        "processed_full.sort_values(['date','tic'],ignore_index=True).head(5)\n",
        "\n",
        "processed_full.to_csv('processed_full.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RrJiFbSPKE2"
      },
      "source": [
        "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
        "trade = data_split(processed_full, '2020-05-01','2021-10-01')\n",
        "print(len(train))\n",
        "print(len(trade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub4JTTRcPOel"
      },
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST) * stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiF95zXgPTsd"
      },
      "source": [
        "#Defining the environment kwargs\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4\n",
        "    \n",
        "}\n",
        "#Instantiate the training gym compatible environment\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "892NcZALPWHF"
      },
      "source": [
        "#Instantiate the training environment\n",
        "# Also instantiate our training gent\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))\n",
        "agent = DRLAgent(env = env_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EwB1T8opX2o"
      },
      "source": [
        "#Instantiate the trading environment\n",
        "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, **env_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOynTQluppye"
      },
      "source": [
        "## TUNING HYPERPARAMETERS USING OPTUNA\n",
        "1. Go to this [link](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/hyperparams_opt.py), you will find all possible hyperparamters to tune for all the models.\n",
        "2. For your model, grab those hyperparamters which you want to optimize and then return a dictionary of hyperparamters.\n",
        "3. There is a feature in Optuna called as hyperparamters importance, you can point out those hyperparamters which are important for tuning.\n",
        "4. By default Optuna use [TPESampler](https://www.youtube.com/watch?v=tdwgR1AqQ8Y) for sampling hyperparamters from the search space. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vojRvAsP2ja"
      },
      "source": [
        "def sample_ddpg_params(trial:optuna.Trial):\n",
        "  # Size of the replay buffer\n",
        "  buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
        "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
        "  \n",
        "  return {\"buffer_size\": buffer_size,\n",
        "          \"learning_rate\":learning_rate,\n",
        "          \"batch_size\":batch_size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ddpg_params_all(trial:optuna.Trial,\n",
        "                           # fixed values from previous study\n",
        "                           learning_rate=0.0103,\n",
        "                           batch_size=128,\n",
        "                           buffer_size=int(1e6)):\n",
        "\n",
        "    gamma = trial.suggest_categorical(\"gamma\", [0.94, 0.96, 0.98])\n",
        "    # Polyak coeff\n",
        "    tau = trial.suggest_categorical(\"tau\", [0.08, 0.1, 0.12])\n",
        "\n",
        "    train_freq = trial.suggest_categorical(\"train_freq\", [512,768,1024])\n",
        "    gradient_steps = train_freq\n",
        "    \n",
        "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
        "    noise_std = trial.suggest_categorical(\"noise_std\", [.1,.2,.3] )\n",
        "\n",
        "    # NOTE: Add \"verybig\" to net_arch when tuning HER (see TD3)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"big\"])\n",
        "    # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
        "\n",
        "    net_arch = {\n",
        "        \"small\": [64, 64],\n",
        "        \"medium\": [256, 256],\n",
        "        \"big\": [512, 512],\n",
        "    }[net_arch]\n",
        "  \n",
        "    hyperparams = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"buffer_size\": buffer_size,\n",
        "        \"gamma\": gamma,\n",
        "        \"gradient_steps\": gradient_steps,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"tau\": tau,\n",
        "        \"train_freq\": train_freq,\n",
        "        #\"noise_std\": noise_std,\n",
        "        #\"noise_type\": noise_type,\n",
        "        \n",
        "        \"policy_kwargs\": dict(net_arch=net_arch)\n",
        "    }\n",
        "    print(hyperparams.keys())\n",
        "    return hyperparams\n"
      ],
      "metadata": {
        "id": "0MIVEjmxhwOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRADE PERFORMANCE CODE\n",
        "Follows in cells below\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "mPAvpM-CTJE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAIN METHOD\n",
        "# called from objective method\n",
        "# returns selected trade perf metric(s)\n",
        "# Calculating Trade Performance for Objective\n",
        "# Need actions and associated prices\n",
        "# Select TF metric\n",
        "# TODO Long-term create DI with multiple metrics\n",
        "# TODO immediate\n",
        "  # set threshold in logging c/b\n",
        "def calc_trade_perf_metric(df_actions, \n",
        "                           df_prices_trade,\n",
        "                           tp_metric,\n",
        "                           dbg=False,\n",
        "                           dummy=False\n",
        "                           ):\n",
        "  \n",
        "    df_actions_p, df_prices_p, tics = prep_data(df_actions.copy(),\n",
        "                                            df_prices_trade.copy())\n",
        "    # actions predicted by trained model on trade data\n",
        "    df_actions_p.to_csv('df_actions.csv') \n",
        "\n",
        "    if dbg:\n",
        "          import pdb; pdb.set_trace()\n",
        "    \n",
        "    tics_buysell, tics_buyonly = segregate_tics_type(df_actions_p)\n",
        "    \n",
        "    # include sync n samples (that is, dates)\n",
        "    df_actions_s, df_prices_s, tics_prtfl = \\\n",
        "        sync_tickers(df_actions_p.copy(),df_prices_p.copy(),tics)\n",
        "    \n",
        "    perf_data= calc_trade_init_vals(df_actions_s, df_prices_s, tics=tics_prtfl)\n",
        "    \n",
        "    pnl_bo = calc_pnl_buyonly(perf_data,tics_buyonly)\n",
        "    perf_results=calc_trade_perf(pnl_bo)\n",
        "    pnl_bs=calc_pnl_buysell(perf_data,tics_buysell)\n",
        "    perf_results_bs = calc_trade_perf(pnl_bs)\n",
        "    # integrate results\n",
        "    perf_results.update(perf_results_bs)\n",
        "    df = pd.DataFrame.from_dict(perf_results, orient='index')\n",
        "    # Temp return dummy metric\n",
        "    \n",
        "    if dummy:\n",
        "        m = np.random.uniform(0,2)\n",
        "        return m\n",
        "    else:\n",
        "        # return element(s) from perf_results\n",
        "        m = calc_trade_metric(df,tp_metric)\n",
        "        print(f'{tp_metric}: {m}')\n",
        "        k = str(len(tpm_hist)+1)\n",
        "        tpm_hist[k] = m\n",
        "        return m\n",
        "        \n"
      ],
      "metadata": {
        "id": "oQkEK8HvLA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Supporting methods\n",
        "\n",
        "def calc_trade_metric(df,metric='avgwl'):\n",
        "    '''# trades', '# wins', '# losses', 'wins total value', 'wins avg value',\n",
        "       'losses total value', 'losses avg value'''\n",
        "    #TO DO formalize methods and max/min vals\n",
        "    tpm_mult = 1.0\n",
        "    avgwl_no_losses = 25\n",
        "    if metric == 'avgwl':\n",
        "        if sum(df['# losses']) == 0:\n",
        "          try:\n",
        "            return max(tpm_hist.values())*tpm_mult\n",
        "          except ValueError:\n",
        "            return avgwl_no_losses\n",
        "        avg_w = sum(df['wins total value'])/sum(df['# wins'])\n",
        "        avg_l = sum(df['losses total value'])/sum(df['# losses'])\n",
        "        m = abs(avg_w/avg_l)\n",
        "\n",
        "    return m\n",
        "\n",
        "def prep_data(df_actions,\n",
        "              df_prices_trade):\n",
        "    #print(f'Prices raw file {df_prices_trade.head()}')\n",
        "    print(f'Prices raw file shape {df_prices_trade.shape}')\n",
        "    #print(f'Actions file {df_actions.head()}')\n",
        "    print(f'Actions file shape {df_actions.shape}')\n",
        "    df=df_prices_trade[['date','close','tic']]\n",
        "    df['Date'] = pd.to_datetime(df['date'])\n",
        "    df = df.set_index('Date')\n",
        "    # set indices on both df to datetime\n",
        "    idx = pd.to_datetime(df_actions.index, infer_datetime_format=True)\n",
        "    df_actions.index=idx\n",
        "    tics = np.unique(df.tic)\n",
        "    #print(tics)\n",
        "    n_tics = len(tics)\n",
        "    print(f'tics: {tics} n_tics: {n_tics}')\n",
        "    dategr = df.groupby('tic')\n",
        "    p_d={t:dategr.get_group(t).loc[:,'close'] for t in tics}\n",
        "    df_prices = pd.DataFrame.from_dict(p_d)\n",
        "    df_prices.index = df_prices.index.normalize()\n",
        "    print(f'Price file shape {df_prices.shape}')\n",
        "    #print(f'Price file index {df_prices.index}')\n",
        "    return df_actions, df_prices, tics\n",
        "\n",
        "\n",
        "# prepares for integrating action and price files\n",
        "def link_prices_actions(df_a,\n",
        "                        df_p):\n",
        "    cols_a = [t + '_a' for t in df_a.columns]\n",
        "    df_a.columns = cols_a\n",
        "    cols_p = [t + '_p' for t in df_p.columns]\n",
        "    df_p.columns = cols_p\n",
        "    return df_a, df_p\n",
        "\n",
        "def sync_tickers(df_actions,df_tickers_p,tickers):\n",
        "    # Some DOW30 components may not be included in portfolio\n",
        "    # passed tickers includes all DOW30 components\n",
        "    # actions and ticker files may have different length indices\n",
        "    if len(df_actions) != len(df_tickers_p):\n",
        "      msng_dates = set(df_actions.index)^set(df_tickers_p.index)\n",
        "      try:\n",
        "        #assumption is prices has one additional timestamp (row)\n",
        "        df_tickers_p.drop(msng_dates,inplace=True)\n",
        "      except:\n",
        "        df_actions.drop(msng_dates,inplace=True)\n",
        "    df_actions, df_tickers_p = link_prices_actions(df_actions,df_tickers_p)\n",
        "    # identify any DOW components not in portfolio\n",
        "    t_not_in_a = [t for t in tickers if t + '_a' not in list(df_actions.columns)]\n",
        "    #t_not_in_p = [t for t in tickers if t + '_p' not in list(df_tickers_p.columns)]\n",
        "    # remove t_not_in_a from df_tickers_p\n",
        "    drop_cols = [t + '_p' for t in t_not_in_a]\n",
        "    df_tickers_p.drop(columns=drop_cols,inplace=True)\n",
        "    # Tickers in portfolio\n",
        "    tickers_prtfl = [c.split('_')[0] for c in df_actions.columns]\n",
        "    return df_actions,df_tickers_p, tickers_prtfl\n",
        "\n",
        "def segregate_tics_type(df_actions):\n",
        "    tics = list(df_actions.columns)\n",
        "    tt = df_actions.apply(min)\n",
        "    # tics with redemptions (i.e.,negative share values\n",
        "    tics_buysell = tt[tt < 0].index.values\n",
        "    tics_buysell.sort()\n",
        "    tics_buyonly_set = set(tics) ^ set(tics_buysell)\n",
        "    tics_buyonly = np.array([*tics_buyonly_set])\n",
        "    tics_buyonly.sort()\n",
        "    return tics_buysell,tics_buyonly\n",
        "\n",
        "def calc_trade_init_vals(dfa,dfp,tics):\n",
        "    # action and prices columns have added _a and _p\n",
        "    fnl_prices = []\n",
        "    perf_data = {}\n",
        "    for t in tics:\n",
        "        acts = dfa[t+'_a'].values\n",
        "        prices = dfp[t+'_p'].values\n",
        "        #tvals_init = [a*p for a, p in zip(acts,prices)]\n",
        "        tvals_init = np.multiply(acts,prices)\n",
        "        d={'actions':acts, 'prices':prices,'init_values':tvals_init}\n",
        "        perf_data[t]=d\n",
        "\n",
        "    return perf_data\n",
        "\n",
        "def calc_pnl_buyonly(perf_data,tics_buyonly):\n",
        "    # assumes all positions held until end of trading period\n",
        "    # no sales/redemptions\n",
        "    # compare purchase/entry price to final price to calc gain/loss\n",
        "    # tickers with redemptions are processed separately\n",
        "    tics_buyonly.sort()\n",
        "    pnl_d = {}\n",
        "    for t in tics_buyonly:\n",
        "        init_values = perf_data[t]['init_values']\n",
        "        prices = perf_data[t]['prices']\n",
        "        actions = perf_data[t]['actions']\n",
        "        fnl_price = prices[-1]\n",
        "        final_values = np.multiply(fnl_price,actions)\n",
        "        pnl=np.subtract(final_values, init_values)\n",
        "        pnl_d[t] = np.array(pnl)\n",
        "    return pnl_d\n",
        "\n",
        "def calc_pnl_for_open_positions(acts,prices):\n",
        "    # identify any positive share values\n",
        "    pnl = []\n",
        "    fp = prices[-1]\n",
        "    open_pos_arg = np.argwhere(acts>0)\n",
        "    if len(open_pos_arg)==0:return pnl\n",
        "    mkt_vals_open = np.multiply(acts[open_pos_arg], prices[open_pos_arg])\n",
        "    # mkt val at end of testing period\n",
        "    # treat as trades for purposes of calculating pnl at end of testing period\n",
        "    mkt_vals_final = np.multiply(fp, acts[open_pos_arg])\n",
        "    pnl = np.subtract(mkt_vals_final, mkt_vals_open)\n",
        "    print(f'Market value of open positions at end of testing {pnl}')\n",
        "    return pnl\n",
        "\n",
        "def calc_pnl_buysell(perf_dict, tics_buysell):\n",
        "    #TODO main question is associating sale with original purchase\n",
        "    # process sales trades\n",
        "    pnl_all = {}\n",
        "    for tic in tics_buysell:\n",
        "        pnl_t = []\n",
        "        tic_data = perf_dict[tic]\n",
        "        acts = tic_data['actions']\n",
        "        prices = tic_data['prices']\n",
        "        cs = np.cumsum(acts)\n",
        "        # copy acts: acts_rev will be revised based on closing/reducing init positions\n",
        "        acts_rev = acts.copy()\n",
        "        # find args of sales actions\n",
        "        args_s = [i + 1 for i in range(len(cs) - 1) if cs[i + 1] < cs[i]]\n",
        "        for s in args_s:  # s is scaler\n",
        "                # need list to hold scaler values for np concat\n",
        "                #price_s = [prices[s]]\n",
        "                act_s = [acts_rev[s]]\n",
        "                args_b = [i for i in range(s) if acts_rev[i] > 0]\n",
        "                prcs_init_trades = prices[args_b]\n",
        "                acts_init_trades = acts_rev[args_b]\n",
        "                #print(f'Lengths of trades/prices {len(acts_init_trades)}, {len(prcs_init_trades)}')\n",
        "                # update actions for sales\n",
        "                # reduce/eliminate init values through trades\n",
        "                # always start with earliest purchase that has not been closed through sale\n",
        "                # selectors for purchase and sales trades\n",
        "                # find earliest remaining purchase\n",
        "                arg_sel = min(args_b)\n",
        "                #sel_s = len(acts_trades) - 1\n",
        "\n",
        "                # closing part/all of earliest init trade not yet closed\n",
        "                # sales actions are negative\n",
        "                # in this test case, abs_val of init and sales share counts are same\n",
        "                # zero-out sales actions\n",
        "                # market value of sale\n",
        "                # max number of shares to be closed: may be less than # originally purchased\n",
        "                acts_shares = min(abs(act_s.pop()), acts_rev[arg_sel])\n",
        "\n",
        "                # mv of shares when purchased\n",
        "                mv_p = abs(acts_shares * prices[arg_sel])\n",
        "                # mv of sold shares\n",
        "                mv_s = abs(acts_shares*prices[s])\n",
        "\n",
        "                # calc pnl\n",
        "                pnl = mv_s - mv_p\n",
        "                # reduce init share count\n",
        "                # close all/part of init purchase\n",
        "                acts_rev[arg_sel] -= acts_shares\n",
        "                acts_rev[s] += acts_shares\n",
        "                # calculate pnl for trade\n",
        "                # value of associated purchase\n",
        "\n",
        "                # find earliest non-zero positive act in acts_revs\n",
        "                #print(pnl)\n",
        "                pnl_t.append(pnl)\n",
        "        print(f'PnL for tic {tic} {pnl_t}')\n",
        "        pnl_op = calc_pnl_for_open_positions(acts_rev,prices)\n",
        "        pnl_t.extend(pnl_op)\n",
        "        pnl_all[tic]=np.array(pnl_t)\n",
        "    return pnl_all\n",
        "\n",
        "def calc_trade_perf(pnl_d):\n",
        "    perf_results = {}\n",
        "    for t,pnl in pnl_d.items():\n",
        "        wins = pnl[pnl>0]  # total val\n",
        "        losses = pnl[pnl<0]\n",
        "        n_wins = len(wins)\n",
        "        n_losses = len(losses)\n",
        "        n_trades = n_wins + n_losses\n",
        "        wins_val = np.sum(wins)\n",
        "        losses_val = np.sum(losses)\n",
        "        wins_avg = 0 if n_wins==0 else np.mean(wins)\n",
        "        #print(f'{t} n_wins: {n_wins} n_losses: {n_losses}')\n",
        "        losses_avg = 0 if n_losses==0 else np.mean(losses)\n",
        "        d = {'# trades':n_trades,'# wins':n_wins,'# losses':n_losses,\n",
        "             'wins total value':wins_val, 'wins avg value':wins_avg,\n",
        "             'losses total value':losses_val, 'losses avg value':losses_avg,}\n",
        "        perf_results[t] = d\n",
        "    return perf_results"
      ],
      "metadata": {
        "id": "GJipWp6UByzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL7LeLeWrj6H"
      },
      "source": [
        "#Calculate the Sharpe ratio\n",
        "#This is our objective for tuning\n",
        "def calculate_sharpe(df):\n",
        "  df['daily_return'] = df['account_value'].pct_change(1)\n",
        "  if df['daily_return'].std() !=0:\n",
        "    sharpe = (252**0.5)*df['daily_return'].mean()/ \\\n",
        "          df['daily_return'].std()\n",
        "    return sharpe\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCRy_kL648DM"
      },
      "source": [
        "## CALLBACKS\n",
        "1. The callback will terminate if the improvement margin is below certain point\n",
        "2. It will terminate after certain number of trial_number are reached, not before that\n",
        "3. It will hold its patience to reach the threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTPSF3bpHDUT"
      },
      "source": [
        "class LoggingCallback:\n",
        "    def __init__(self,threshold,trial_number,patience):\n",
        "      '''\n",
        "      threshold:int tolerance for increase in sharpe ratio\n",
        "      trial_number: int Prune after minimum number of trials\n",
        "      patience: int patience for the threshold\n",
        "      '''\n",
        "      self.threshold = threshold\n",
        "      self.trial_number  = trial_number\n",
        "      self.patience = patience\n",
        "      print(f'Callback threshold {self.threshold}, \\\n",
        "            trial_number {self.trial_number}, \\\n",
        "            patience {self.patience}')\n",
        "      self.cb_list = [] #Trials list for which threshold is reached\n",
        "    def __call__(self,study:optuna.study, frozen_trial:optuna.Trial):\n",
        "      #Setting the best value in the current trial\n",
        "      study.set_user_attr(\"previous_best_value\", study.best_value)\n",
        "      \n",
        "      #Checking if the minimum number of trials have pass\n",
        "      if frozen_trial.number >self.trial_number:\n",
        "          previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
        "          #Checking if the previous and current objective values have the same sign\n",
        "          if previous_best_value * study.best_value >=0:\n",
        "              #Checking for the threshold condition\n",
        "              if abs(previous_best_value-study.best_value) < self.threshold: \n",
        "                  self.cb_list.append(frozen_trial.number)\n",
        "                  #If threshold is achieved for the patience amount of time\n",
        "                  if len(self.cb_list)>self.patience:\n",
        "                      print('The study stops now...')\n",
        "                      print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
        "                      print('The previous and current best values are {} and {} respectively'\n",
        "                              .format(previous_best_value, study.best_value))\n",
        "                      study.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsEKc-9APaS1"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import sys   \n",
        "\n",
        "os.makedirs(\"models\",exist_ok=True)\n",
        "\n",
        "def objective(trial:optuna.Trial):\n",
        "  #Trial will suggest a set of hyperparamters from the specified range\n",
        "  hyperparameters = sample_ddpg_params_all(trial)\n",
        "  print(f'HP params from objective: {hyperparameters.keys()}')\n",
        "  policy_kwargs = None  # default\n",
        "  if 'policy_kwargs' in hyperparameters.keys():\n",
        "    policy_kwargs = hyperparameters['policy_kwargs']\n",
        "    del hyperparameters['policy_kwargs']\n",
        "    print(f'pol kw args {policy_kwargs}')\n",
        "  model_ddpg = agent.get_model(\"ddpg\",\n",
        "                               policy_kwargs = policy_kwargs,\n",
        "                               model_kwargs = hyperparameters )\n",
        "  #You can increase it for better comparison\n",
        "  trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                                   tb_log_name=\"ddpg\",\n",
        "                                   total_timesteps=total_timesteps)\n",
        "  trained_ddpg.save('models/ddpg_{}.pth'.format(trial.number))\n",
        "  clear_output(wait=True)\n",
        "  #For the given hyperparamters, determine the account value in the trading period\n",
        "  df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_trade_gym)\n",
        "  '''\n",
        "  #Calculate sharpe from the account value\n",
        "  sharpe = calculate_sharpe(df_account_value)\n",
        "  print(f'Shape df_account_value: {df_account_value.shape}')\n",
        "  print(df_account_value.head())\n",
        "  print(f'Shape df_actions: {df_actions.shape}')\n",
        "  print(df_actions.head())\n",
        "\n",
        "  return sharpe\n",
        "  '''\n",
        "  # Calculate trade performance metric\n",
        "  # TODO allow selection of metric\n",
        "  tpm = calc_trade_perf_metric(df_actions,trade,tp_metric)\n",
        "  return tpm\n",
        "\n",
        "#Create a study object and specify the direction as 'maximize'\n",
        "#As you want to maximize sharpe\n",
        "#Pruner stops not promising iterations\n",
        "#Use a pruner, else you will get error related to divergence of model\n",
        "#You can also use Multivariate samplere\n",
        "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "study = optuna.create_study(study_name=\"ddpg_study\",direction='maximize',\n",
        "                            sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
        "\n",
        "logging_callback = LoggingCallback(threshold=\n",
        "                                   lc_threshold,\n",
        "                                   patience=lc_patience,\n",
        "                                   trial_number=lc_trial_number)\n",
        "#You can increase the n_trials for a better search space scanning\n",
        "study.optimize(objective, n_trials=n_trials,catch=(ValueError,),callbacks=[logging_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg7LRlHmj9GB"
      },
      "source": [
        "joblib.dump(study, \"final_ddpg_study__.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVMue1-xuGHC"
      },
      "source": [
        "#Get the best hyperparamters\n",
        "print('Hyperparameters after tuning',study.best_params)\n",
        "print('Hyperparameters before tuning',config.DDPG_PARAMS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsZmMw0ykmYo"
      },
      "source": [
        "study.best_trial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fETqKJj4uSi5"
      },
      "source": [
        "from stable_baselines3 import DDPG\n",
        "tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=env_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgchX1LLuua-"
      },
      "source": [
        "#Trading period account value with tuned model\n",
        "df_account_value_tuned, df_actions_tuned = DRLAgent.DRL_prediction(\n",
        "    model=tuned_model_ddpg, \n",
        "    environment = e_trade_gym)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "df_actions_tuned.to_csv(\"./\"+config.RESULTS_DIR+\"/tuned_actions_\" +now+ '.csv')"
      ],
      "metadata": {
        "id": "-blnTnoI1F65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s5KNvVuvr2D"
      },
      "source": [
        "#Backtesting with our pruned model\n",
        "print(\"==============Get Backtest Results===========\")\n",
        "print(\"==============Pruned Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all_tuned = backtest_stats(account_value=df_account_value_tuned)\n",
        "perf_stats_all_tuned = pd.DataFrame(perf_stats_all_tuned)\n",
        "perf_stats_all_tuned.columns = ['Value']\n",
        "# add trade performance metric\n",
        "tpm = calc_trade_perf_metric(df_actions_tuned,trade,tp_metric)\n",
        "trp_metric = {'Value':tpm}\n",
        "df2 = pd.DataFrame(trp_metric,index=['Trade_Perf'])\n",
        "perf_stats_all_tuned = perf_stats_all_tuned.append(df2)\n",
        "perf_stats_all_tuned.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_tuned_\"+now+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuGaI9lSvvVD"
      },
      "source": [
        "#Now train with not tuned hyperaparameters\n",
        "#Default config.ddpg_PARAMS\n",
        "non_tuned_model_ddpg = agent.get_model(\"ddpg\",model_kwargs = config.DDPG_PARAMS )\n",
        "trained_ddpg = agent.train_model(model=non_tuned_model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=total_timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZbEYRQ1wBeC"
      },
      "source": [
        "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_trade_gym)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFdB4YM3wh0m"
      },
      "source": [
        "#Backtesting for not tuned hyperparamters\n",
        "print(\"==============Get Backtest Results===========\")\n",
        "print(\"============Default Hyperparameters==========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "# perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12fxdvUZwi_W"
      },
      "source": [
        "#You can see with trial, our sharpe ratio is increasing\n",
        "#Certainly you can afford more number of trials for further optimization\n",
        "from optuna.visualization import plot_optimization_history\n",
        "fig = plot_optimization_history(study)\n",
        "#\"./\"+config.RESULTS_DIR+\n",
        "fig.write_image(\"./\"+config.RESULTS_DIR+\"/opt_hist.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUF2GvAx6-k"
      },
      "source": [
        "from optuna.visualization import plot_contour\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jkqeSUIyCT0"
      },
      "source": [
        "#Hyperparamters importance\n",
        "#Ent_coef is the most important\n",
        "fig = plot_param_importances(study)\n",
        "fig.write_image(\"./\"+config.RESULTS_DIR+\"/params_importances.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAD0MIAWukB9"
      },
      "source": [
        "## FURTHER WORKS\n",
        "\n",
        "1.   You can tune more critical hyperparameters\n",
        "2.   Multi-objective hyperparameter optimization using Optuna. Here we can maximize Sharpe and simultaneously minimize Volatility in our account value to tune our hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_edBJqB8yEDr"
      },
      "source": [
        "plot_edf(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXTgG1yvgeyq"
      },
      "source": [
        "files.download('/content/final_ddpg_study__.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}